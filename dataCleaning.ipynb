{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b54fe1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07e90a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/typing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "950ff326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sessionIndex</th>\n",
       "      <th>rep</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>-0.0496</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>s057</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.1018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20400 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n",
       "0        s002             1    1    0.1491       0.3979       0.2488  0.1069   \n",
       "1        s002             1    2    0.1111       0.3451       0.2340  0.0694   \n",
       "2        s002             1    3    0.1328       0.2072       0.0744  0.0731   \n",
       "3        s002             1    4    0.1291       0.2515       0.1224  0.1059   \n",
       "4        s002             1    5    0.1249       0.2317       0.1068  0.0895   \n",
       "...       ...           ...  ...       ...          ...          ...     ...   \n",
       "20395    s057             8   46    0.0884       0.0685      -0.0199  0.1095   \n",
       "20396    s057             8   47    0.0655       0.0630      -0.0025  0.0910   \n",
       "20397    s057             8   48    0.0939       0.1189       0.0250  0.1008   \n",
       "20398    s057             8   49    0.0923       0.1294       0.0371  0.0913   \n",
       "20399    s057             8   50    0.0596       0.1310       0.0714  0.0992   \n",
       "\n",
       "       DD.t.i  UD.t.i     H.i  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "0      0.1674  0.0605  0.1169  ...  0.1349  0.1484  0.0135  0.0932  0.3515   \n",
       "1      0.1283  0.0589  0.0908  ...  0.1412  0.2558  0.1146  0.1146  0.2642   \n",
       "2      0.1291  0.0560  0.0821  ...  0.1621  0.2332  0.0711  0.1172  0.2705   \n",
       "3      0.2495  0.1436  0.1040  ...  0.1457  0.1629  0.0172  0.0866  0.2341   \n",
       "4      0.1676  0.0781  0.0903  ...  0.1312  0.1582  0.0270  0.0884  0.2517   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "20395  0.1290  0.0195  0.0945  ...  0.1219  0.1383  0.0164  0.0820  0.1329   \n",
       "20396  0.1148  0.0238  0.0916  ...  0.1008  0.0512 -0.0496  0.1037  0.0868   \n",
       "20397  0.1122  0.0114  0.0721  ...  0.0913  0.1169  0.0256  0.0689  0.1311   \n",
       "20398  0.0990  0.0077  0.0992  ...  0.0882  0.0821 -0.0061  0.0576  0.0697   \n",
       "20399  0.1103  0.0111  0.0998  ...  0.0969  0.0784 -0.0185  0.0790  0.1133   \n",
       "\n",
       "       UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "0      0.2583  0.1338       0.3509       0.2171    0.0742  \n",
       "1      0.1496  0.0839       0.2756       0.1917    0.0747  \n",
       "2      0.1533  0.1085       0.2847       0.1762    0.0945  \n",
       "3      0.1475  0.0845       0.3232       0.2387    0.0813  \n",
       "4      0.1633  0.0903       0.2517       0.1614    0.0818  \n",
       "...       ...     ...          ...          ...       ...  \n",
       "20395  0.0509  0.1005       0.2054       0.1049    0.1047  \n",
       "20396 -0.0169  0.1445       0.2206       0.0761    0.1198  \n",
       "20397  0.0622  0.1034       0.2017       0.0983    0.0905  \n",
       "20398  0.0121  0.0979       0.1917       0.0938    0.0931  \n",
       "20399  0.0343  0.0807       0.1993       0.1186    0.1018  \n",
       "\n",
       "[20400 rows x 34 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51ee152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject            0\n",
       "sessionIndex       0\n",
       "rep                0\n",
       "H.period           0\n",
       "DD.period.t        0\n",
       "UD.period.t        0\n",
       "H.t                0\n",
       "DD.t.i             0\n",
       "UD.t.i             0\n",
       "H.i                0\n",
       "DD.i.e             0\n",
       "UD.i.e             0\n",
       "H.e                0\n",
       "DD.e.five          0\n",
       "UD.e.five          0\n",
       "H.five             0\n",
       "DD.five.Shift.r    0\n",
       "UD.five.Shift.r    0\n",
       "H.Shift.r          0\n",
       "DD.Shift.r.o       0\n",
       "UD.Shift.r.o       0\n",
       "H.o                0\n",
       "DD.o.a             0\n",
       "UD.o.a             0\n",
       "H.a                0\n",
       "DD.a.n             0\n",
       "UD.a.n             0\n",
       "H.n                0\n",
       "DD.n.l             0\n",
       "UD.n.l             0\n",
       "H.l                0\n",
       "DD.l.Return        0\n",
       "UD.l.Return        0\n",
       "H.Return           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e986959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.subject.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b01ac3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.2038</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>-0.0188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>-0.0280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>-0.0496</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.1018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20400 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i  \\\n",
       "0        s002    0.1491       0.3979       0.2488  0.1069  0.1674  0.0605   \n",
       "1        s002    0.1111       0.3451       0.2340  0.0694  0.1283  0.0589   \n",
       "2        s002    0.1328       0.2072       0.0744  0.0731  0.1291  0.0560   \n",
       "3        s002    0.1291       0.2515       0.1224  0.1059  0.2495  0.1436   \n",
       "4        s002    0.1249       0.2317       0.1068  0.0895  0.1676  0.0781   \n",
       "...       ...       ...          ...          ...     ...     ...     ...   \n",
       "20395    s057    0.0884       0.0685      -0.0199  0.1095  0.1290  0.0195   \n",
       "20396    s057    0.0655       0.0630      -0.0025  0.0910  0.1148  0.0238   \n",
       "20397    s057    0.0939       0.1189       0.0250  0.1008  0.1122  0.0114   \n",
       "20398    s057    0.0923       0.1294       0.0371  0.0913  0.0990  0.0077   \n",
       "20399    s057    0.0596       0.1310       0.0714  0.0992  0.1103  0.0111   \n",
       "\n",
       "          H.i  DD.i.e  UD.i.e  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "0      0.1169  0.2212  0.1043  ...  0.1349  0.1484  0.0135  0.0932  0.3515   \n",
       "1      0.0908  0.1357  0.0449  ...  0.1412  0.2558  0.1146  0.1146  0.2642   \n",
       "2      0.0821  0.1542  0.0721  ...  0.1621  0.2332  0.0711  0.1172  0.2705   \n",
       "3      0.1040  0.2038  0.0998  ...  0.1457  0.1629  0.0172  0.0866  0.2341   \n",
       "4      0.0903  0.1589  0.0686  ...  0.1312  0.1582  0.0270  0.0884  0.2517   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "20395  0.0945  0.0757 -0.0188  ...  0.1219  0.1383  0.0164  0.0820  0.1329   \n",
       "20396  0.0916  0.0636 -0.0280  ...  0.1008  0.0512 -0.0496  0.1037  0.0868   \n",
       "20397  0.0721  0.0462 -0.0259  ...  0.0913  0.1169  0.0256  0.0689  0.1311   \n",
       "20398  0.0992  0.0897 -0.0095  ...  0.0882  0.0821 -0.0061  0.0576  0.0697   \n",
       "20399  0.0998  0.0813 -0.0185  ...  0.0969  0.0784 -0.0185  0.0790  0.1133   \n",
       "\n",
       "       UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "0      0.2583  0.1338       0.3509       0.2171    0.0742  \n",
       "1      0.1496  0.0839       0.2756       0.1917    0.0747  \n",
       "2      0.1533  0.1085       0.2847       0.1762    0.0945  \n",
       "3      0.1475  0.0845       0.3232       0.2387    0.0813  \n",
       "4      0.1633  0.0903       0.2517       0.1614    0.0818  \n",
       "...       ...     ...          ...          ...       ...  \n",
       "20395  0.0509  0.1005       0.2054       0.1049    0.1047  \n",
       "20396 -0.0169  0.1445       0.2206       0.0761    0.1198  \n",
       "20397  0.0622  0.1034       0.2017       0.0983    0.0905  \n",
       "20398  0.0121  0.0979       0.1917       0.0938    0.0931  \n",
       "20399  0.0343  0.0807       0.1993       0.1186    0.1018  \n",
       "\n",
       "[20400 rows x 32 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data.drop(['sessionIndex','rep'],axis=\"columns\")\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68f83d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>-0.0301</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.0866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.2599</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.0779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1839</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.2643</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.0631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1716</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.0821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.1841</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1568</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.2666</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.4134</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.1277</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.2313</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.0845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.1393</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>-0.0813</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.1006</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>-0.0794</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.0940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>s002</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.2971</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject  H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i  \\\n",
       "9      s002    0.1093       0.1807       0.0714  0.0731  0.1457  0.0726   \n",
       "11     s002    0.0911       0.1525       0.0614  0.0824  0.1516  0.0692   \n",
       "15     s002    0.1270       0.1839       0.0569  0.0911  0.1381  0.0470   \n",
       "21     s002    0.1072       0.2217       0.1145  0.0726  0.1349  0.0623   \n",
       "22     s002    0.1243       0.1841       0.0598  0.0768  0.1568  0.0800   \n",
       "..      ...       ...          ...          ...     ...     ...     ...   \n",
       "348    s002    0.1064       0.1277       0.0213  0.0853  0.1473  0.0620   \n",
       "349    s002    0.1029       0.1393       0.0364  0.0729  0.1278  0.0549   \n",
       "354    s002    0.1428       0.2256       0.0828  0.0961  0.1199  0.0238   \n",
       "361    s002    0.1417       0.1957       0.0540  0.0940  0.1389  0.0449   \n",
       "395    s002    0.1502       0.2114       0.0612  0.0650  0.1302  0.0652   \n",
       "\n",
       "        H.i  DD.i.e  UD.i.e  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "9    0.0766  0.1241  0.0475  ...  0.1463  0.1162 -0.0301  0.1207  0.2281   \n",
       "11   0.0731  0.1391  0.0660  ...  0.1465  0.1492  0.0027  0.0758  0.2201   \n",
       "15   0.0895  0.1774  0.0879  ...  0.1338  0.1521  0.0183  0.0774  0.1954   \n",
       "21   0.0768  0.1716  0.0948  ...  0.1259  0.1373  0.0114  0.0845  0.2009   \n",
       "22   0.0850  0.1539  0.0689  ...  0.1161  0.1362  0.0201  0.0679  0.2666   \n",
       "..      ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "348  0.0797  0.1135  0.0338  ...  0.1008  0.1225  0.0217  0.0845  0.1705   \n",
       "349  0.0771  0.0982  0.0211  ...  0.1122  0.1342  0.0220  0.0776  0.1731   \n",
       "354  0.1154  0.1344  0.0190  ...  0.1513  0.0700 -0.0813  0.1115  0.1669   \n",
       "361  0.1006  0.1320  0.0314  ...  0.1315  0.0521 -0.0794  0.1243  0.2647   \n",
       "395  0.0985  0.1249  0.0264  ...  0.1212  0.1587  0.0375  0.0845  0.1990   \n",
       "\n",
       "     UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "9    0.1074  0.1204       0.3187       0.1983    0.0866  \n",
       "11   0.1443  0.0742       0.2599       0.1857    0.0779  \n",
       "15   0.1180  0.0942       0.2643       0.1701    0.0631  \n",
       "21   0.1164  0.0927       0.2654       0.1727    0.0821  \n",
       "22   0.1987  0.1222       0.4134       0.2912    0.0700  \n",
       "..      ...     ...          ...          ...       ...  \n",
       "348  0.0860  0.1061       0.2313       0.1252    0.0845  \n",
       "349  0.0955  0.0884       0.2158       0.1274    0.1072  \n",
       "354  0.0554  0.1420       0.2984       0.1564    0.1132  \n",
       "361  0.1404  0.1185       0.2517       0.1332    0.0940  \n",
       "395  0.1145  0.1061       0.2971       0.1910    0.1014  \n",
       "\n",
       "[269 rows x 32 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s002_data = data1[data1['subject'] == 's002']\n",
    "numeric_data = s002_data.select_dtypes(include=\"number\")\n",
    "stds = numeric_data.std()\n",
    "means = numeric_data.mean()\n",
    "\n",
    "is_high = numeric_data>(means+2.3*stds)\n",
    "is_low = numeric_data<(means-2.3*stds)\n",
    "\n",
    "outliers = is_high | is_low\n",
    "\n",
    "outliers_df = numeric_data[outliers.any(axis=1)]\n",
    "clean_df = s002_data[~outliers.any(axis=1)]\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d4218c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nots002_data = data1[data1['subject'] != 's002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48f3b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nots002_data = nots002_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23b163c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>s003</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.2997</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>s003</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>0.1214</td>\n",
       "      <td>0.1908</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.3201</td>\n",
       "      <td>0.2063</td>\n",
       "      <td>0.1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>s003</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.1656</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>s003</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2296</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.6038</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.5352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.3079</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>s003</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.5223</td>\n",
       "      <td>0.4048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>0.1755</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>0.1661</td>\n",
       "      <td>0.0987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>-0.0188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>-0.0280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>-0.0496</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>s057</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.1018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i  \\\n",
       "400      s003    0.1333       0.2636       0.1303  0.1246  0.1737  0.0491   \n",
       "401      s003    0.1307       0.3850       0.2543  0.1214  0.1908  0.0694   \n",
       "402      s003    0.1143       0.2752       0.1609  0.1148  0.1439  0.0291   \n",
       "403      s003    0.1328       0.2296       0.0968  0.0985  0.7023  0.6038   \n",
       "404      s003    0.1217       0.1863       0.0646  0.1175  0.1584  0.0409   \n",
       "...       ...       ...          ...          ...     ...     ...     ...   \n",
       "20395    s057    0.0884       0.0685      -0.0199  0.1095  0.1290  0.0195   \n",
       "20396    s057    0.0655       0.0630      -0.0025  0.0910  0.1148  0.0238   \n",
       "20397    s057    0.0939       0.1189       0.0250  0.1008  0.1122  0.0114   \n",
       "20398    s057    0.0923       0.1294       0.0371  0.0913  0.0990  0.0077   \n",
       "20399    s057    0.0596       0.1310       0.0714  0.0992  0.1103  0.0111   \n",
       "\n",
       "          H.i  DD.i.e  UD.i.e  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "400    0.1330  0.1977  0.0647  ...  0.1291  0.2234  0.0943  0.1090  0.3811   \n",
       "401    0.0956  0.2007  0.1051  ...  0.1016  0.2365  0.1349  0.0781  0.2932   \n",
       "402    0.1468  0.4033  0.2565  ...  0.1132  0.2104  0.0972  0.1351  0.2502   \n",
       "403    0.1222  0.6574  0.5352  ...  0.1470  0.1824  0.0354  0.0892  0.3454   \n",
       "404    0.1175  0.5223  0.4048  ...  0.1288  0.1421  0.0133  0.0618  0.2373   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "20395  0.0945  0.0757 -0.0188  ...  0.1219  0.1383  0.0164  0.0820  0.1329   \n",
       "20396  0.0916  0.0636 -0.0280  ...  0.1008  0.0512 -0.0496  0.1037  0.0868   \n",
       "20397  0.0721  0.0462 -0.0259  ...  0.0913  0.1169  0.0256  0.0689  0.1311   \n",
       "20398  0.0992  0.0897 -0.0095  ...  0.0882  0.0821 -0.0061  0.0576  0.0697   \n",
       "20399  0.0998  0.0813 -0.0185  ...  0.0969  0.0784 -0.0185  0.0790  0.1133   \n",
       "\n",
       "       UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "400    0.2721  0.1003       0.2997       0.1994    0.1035  \n",
       "401    0.2151  0.1138       0.3201       0.2063    0.1035  \n",
       "402    0.1151  0.1227       0.2883       0.1656    0.0800  \n",
       "403    0.2562  0.1090       0.3079       0.1989    0.0958  \n",
       "404    0.1755  0.0971       0.2632       0.1661    0.0987  \n",
       "...       ...     ...          ...          ...       ...  \n",
       "20395  0.0509  0.1005       0.2054       0.1049    0.1047  \n",
       "20396 -0.0169  0.1445       0.2206       0.0761    0.1198  \n",
       "20397  0.0622  0.1034       0.2017       0.0983    0.0905  \n",
       "20398  0.0121  0.0979       0.1917       0.0938    0.0931  \n",
       "20399  0.0343  0.0807       0.1993       0.1186    0.1018  \n",
       "\n",
       "[20000 rows x 32 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nots002_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf4adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data1.groupby(\"subject\").std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4e13a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>H.e</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s002</th>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.169556</td>\n",
       "      <td>0.062598</td>\n",
       "      <td>0.086247</td>\n",
       "      <td>0.150193</td>\n",
       "      <td>0.063946</td>\n",
       "      <td>0.077409</td>\n",
       "      <td>0.126418</td>\n",
       "      <td>0.049009</td>\n",
       "      <td>0.089132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117492</td>\n",
       "      <td>0.121199</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.084263</td>\n",
       "      <td>0.214241</td>\n",
       "      <td>0.129977</td>\n",
       "      <td>0.096058</td>\n",
       "      <td>0.248565</td>\n",
       "      <td>0.152508</td>\n",
       "      <td>0.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s003</th>\n",
       "      <td>0.157293</td>\n",
       "      <td>0.169161</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.134296</td>\n",
       "      <td>0.155552</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.127763</td>\n",
       "      <td>0.143294</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143438</td>\n",
       "      <td>0.122862</td>\n",
       "      <td>-0.020576</td>\n",
       "      <td>0.110990</td>\n",
       "      <td>0.152210</td>\n",
       "      <td>0.041221</td>\n",
       "      <td>0.103004</td>\n",
       "      <td>0.268717</td>\n",
       "      <td>0.165713</td>\n",
       "      <td>0.099209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s004</th>\n",
       "      <td>0.103745</td>\n",
       "      <td>0.201064</td>\n",
       "      <td>0.097319</td>\n",
       "      <td>0.104109</td>\n",
       "      <td>0.148142</td>\n",
       "      <td>0.044033</td>\n",
       "      <td>0.106150</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.020166</td>\n",
       "      <td>0.080580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129352</td>\n",
       "      <td>0.117051</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>0.085273</td>\n",
       "      <td>0.154218</td>\n",
       "      <td>0.068945</td>\n",
       "      <td>0.093692</td>\n",
       "      <td>0.226031</td>\n",
       "      <td>0.132339</td>\n",
       "      <td>0.075529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s005</th>\n",
       "      <td>0.081963</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.196278</td>\n",
       "      <td>0.116951</td>\n",
       "      <td>0.227286</td>\n",
       "      <td>0.110334</td>\n",
       "      <td>0.089127</td>\n",
       "      <td>0.194292</td>\n",
       "      <td>0.105166</td>\n",
       "      <td>0.113709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131529</td>\n",
       "      <td>0.185614</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>0.250916</td>\n",
       "      <td>0.164927</td>\n",
       "      <td>0.087597</td>\n",
       "      <td>0.406607</td>\n",
       "      <td>0.319010</td>\n",
       "      <td>0.092090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s007</th>\n",
       "      <td>0.095211</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>0.081252</td>\n",
       "      <td>0.074890</td>\n",
       "      <td>0.120669</td>\n",
       "      <td>0.045778</td>\n",
       "      <td>0.076754</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>0.028075</td>\n",
       "      <td>0.089969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103193</td>\n",
       "      <td>0.117067</td>\n",
       "      <td>0.013874</td>\n",
       "      <td>0.125255</td>\n",
       "      <td>0.112926</td>\n",
       "      <td>-0.012329</td>\n",
       "      <td>0.096714</td>\n",
       "      <td>0.239116</td>\n",
       "      <td>0.142402</td>\n",
       "      <td>0.083882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s008</th>\n",
       "      <td>0.087904</td>\n",
       "      <td>0.207432</td>\n",
       "      <td>0.119528</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>0.114949</td>\n",
       "      <td>0.031433</td>\n",
       "      <td>0.078263</td>\n",
       "      <td>0.113117</td>\n",
       "      <td>0.034854</td>\n",
       "      <td>0.092462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>0.110634</td>\n",
       "      <td>-0.002865</td>\n",
       "      <td>0.096973</td>\n",
       "      <td>0.119943</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.093137</td>\n",
       "      <td>0.225950</td>\n",
       "      <td>0.132813</td>\n",
       "      <td>0.100621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s010</th>\n",
       "      <td>0.089034</td>\n",
       "      <td>0.149080</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>0.067136</td>\n",
       "      <td>0.147262</td>\n",
       "      <td>0.080126</td>\n",
       "      <td>0.081407</td>\n",
       "      <td>0.119041</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.067630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061829</td>\n",
       "      <td>0.118330</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>0.080376</td>\n",
       "      <td>0.225239</td>\n",
       "      <td>0.144863</td>\n",
       "      <td>0.079028</td>\n",
       "      <td>0.214162</td>\n",
       "      <td>0.135134</td>\n",
       "      <td>0.078380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s011</th>\n",
       "      <td>0.081427</td>\n",
       "      <td>0.165664</td>\n",
       "      <td>0.084237</td>\n",
       "      <td>0.118299</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>0.022176</td>\n",
       "      <td>0.092703</td>\n",
       "      <td>0.143644</td>\n",
       "      <td>0.050940</td>\n",
       "      <td>0.110688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126625</td>\n",
       "      <td>0.105366</td>\n",
       "      <td>-0.021258</td>\n",
       "      <td>0.119474</td>\n",
       "      <td>0.094745</td>\n",
       "      <td>-0.024730</td>\n",
       "      <td>0.112906</td>\n",
       "      <td>0.149493</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.125489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s012</th>\n",
       "      <td>0.140250</td>\n",
       "      <td>0.185625</td>\n",
       "      <td>0.045376</td>\n",
       "      <td>0.124888</td>\n",
       "      <td>0.149185</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>0.133069</td>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>0.127673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162381</td>\n",
       "      <td>0.142180</td>\n",
       "      <td>-0.020200</td>\n",
       "      <td>0.137033</td>\n",
       "      <td>0.130215</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>0.148068</td>\n",
       "      <td>0.304430</td>\n",
       "      <td>0.156362</td>\n",
       "      <td>0.140239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s013</th>\n",
       "      <td>0.080338</td>\n",
       "      <td>0.128903</td>\n",
       "      <td>0.048564</td>\n",
       "      <td>0.071634</td>\n",
       "      <td>0.116411</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.088232</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.061283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097836</td>\n",
       "      <td>0.103268</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.060277</td>\n",
       "      <td>0.143281</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.074938</td>\n",
       "      <td>0.227142</td>\n",
       "      <td>0.152204</td>\n",
       "      <td>0.085247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s015</th>\n",
       "      <td>0.078122</td>\n",
       "      <td>0.168027</td>\n",
       "      <td>0.089905</td>\n",
       "      <td>0.075487</td>\n",
       "      <td>0.104308</td>\n",
       "      <td>0.028820</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.077613</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.078238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086392</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.075132</td>\n",
       "      <td>0.128458</td>\n",
       "      <td>0.053326</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.200053</td>\n",
       "      <td>0.125054</td>\n",
       "      <td>0.072395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s016</th>\n",
       "      <td>0.104281</td>\n",
       "      <td>0.435364</td>\n",
       "      <td>0.331084</td>\n",
       "      <td>0.066853</td>\n",
       "      <td>0.245018</td>\n",
       "      <td>0.178165</td>\n",
       "      <td>0.083918</td>\n",
       "      <td>0.320703</td>\n",
       "      <td>0.236785</td>\n",
       "      <td>0.094588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117256</td>\n",
       "      <td>0.293637</td>\n",
       "      <td>0.176380</td>\n",
       "      <td>0.100993</td>\n",
       "      <td>0.302622</td>\n",
       "      <td>0.201629</td>\n",
       "      <td>0.100716</td>\n",
       "      <td>0.410868</td>\n",
       "      <td>0.310152</td>\n",
       "      <td>0.093568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s017</th>\n",
       "      <td>0.071280</td>\n",
       "      <td>0.186818</td>\n",
       "      <td>0.115538</td>\n",
       "      <td>0.051763</td>\n",
       "      <td>0.121061</td>\n",
       "      <td>0.069298</td>\n",
       "      <td>0.049009</td>\n",
       "      <td>0.097323</td>\n",
       "      <td>0.048314</td>\n",
       "      <td>0.060762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.080817</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.057405</td>\n",
       "      <td>0.167068</td>\n",
       "      <td>0.109663</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.211661</td>\n",
       "      <td>0.141272</td>\n",
       "      <td>0.061676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s018</th>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.161282</td>\n",
       "      <td>0.069653</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.146472</td>\n",
       "      <td>0.056275</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.141473</td>\n",
       "      <td>0.066081</td>\n",
       "      <td>0.081294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113673</td>\n",
       "      <td>0.130511</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>0.125686</td>\n",
       "      <td>0.085284</td>\n",
       "      <td>-0.040403</td>\n",
       "      <td>0.120233</td>\n",
       "      <td>0.304630</td>\n",
       "      <td>0.184397</td>\n",
       "      <td>0.077346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s019</th>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.298299</td>\n",
       "      <td>0.221019</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.274091</td>\n",
       "      <td>0.186591</td>\n",
       "      <td>0.059477</td>\n",
       "      <td>0.095274</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.091478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112876</td>\n",
       "      <td>0.183659</td>\n",
       "      <td>0.070782</td>\n",
       "      <td>0.069474</td>\n",
       "      <td>0.275717</td>\n",
       "      <td>0.206242</td>\n",
       "      <td>0.072334</td>\n",
       "      <td>0.521120</td>\n",
       "      <td>0.448786</td>\n",
       "      <td>0.095091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s020</th>\n",
       "      <td>0.109741</td>\n",
       "      <td>0.207484</td>\n",
       "      <td>0.097743</td>\n",
       "      <td>0.093292</td>\n",
       "      <td>0.159533</td>\n",
       "      <td>0.066241</td>\n",
       "      <td>0.112904</td>\n",
       "      <td>0.152390</td>\n",
       "      <td>0.039485</td>\n",
       "      <td>0.098645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131727</td>\n",
       "      <td>0.179090</td>\n",
       "      <td>0.047362</td>\n",
       "      <td>0.119103</td>\n",
       "      <td>0.157470</td>\n",
       "      <td>0.038366</td>\n",
       "      <td>0.136530</td>\n",
       "      <td>0.251457</td>\n",
       "      <td>0.114927</td>\n",
       "      <td>0.102723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s021</th>\n",
       "      <td>0.099546</td>\n",
       "      <td>0.219191</td>\n",
       "      <td>0.119645</td>\n",
       "      <td>0.086131</td>\n",
       "      <td>0.203666</td>\n",
       "      <td>0.117535</td>\n",
       "      <td>0.090883</td>\n",
       "      <td>0.155242</td>\n",
       "      <td>0.064358</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067404</td>\n",
       "      <td>0.168593</td>\n",
       "      <td>0.101190</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>0.217302</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.095730</td>\n",
       "      <td>0.334604</td>\n",
       "      <td>0.238874</td>\n",
       "      <td>0.084151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s022</th>\n",
       "      <td>0.054491</td>\n",
       "      <td>0.515802</td>\n",
       "      <td>0.461312</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.374969</td>\n",
       "      <td>0.322669</td>\n",
       "      <td>0.047068</td>\n",
       "      <td>0.285859</td>\n",
       "      <td>0.238791</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094672</td>\n",
       "      <td>0.207343</td>\n",
       "      <td>0.112672</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>0.385210</td>\n",
       "      <td>0.331419</td>\n",
       "      <td>0.049452</td>\n",
       "      <td>0.590261</td>\n",
       "      <td>0.540809</td>\n",
       "      <td>0.056212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s024</th>\n",
       "      <td>0.073995</td>\n",
       "      <td>0.207199</td>\n",
       "      <td>0.133205</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>0.171567</td>\n",
       "      <td>0.117895</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>0.140358</td>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.059769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079150</td>\n",
       "      <td>0.132264</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.056814</td>\n",
       "      <td>0.244982</td>\n",
       "      <td>0.188168</td>\n",
       "      <td>0.071531</td>\n",
       "      <td>0.308494</td>\n",
       "      <td>0.236963</td>\n",
       "      <td>0.069065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s025</th>\n",
       "      <td>0.110121</td>\n",
       "      <td>0.209256</td>\n",
       "      <td>0.099134</td>\n",
       "      <td>0.071676</td>\n",
       "      <td>0.145707</td>\n",
       "      <td>0.074031</td>\n",
       "      <td>0.065531</td>\n",
       "      <td>0.126289</td>\n",
       "      <td>0.060758</td>\n",
       "      <td>0.078929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068310</td>\n",
       "      <td>0.111173</td>\n",
       "      <td>0.042863</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.107896</td>\n",
       "      <td>0.092383</td>\n",
       "      <td>0.558323</td>\n",
       "      <td>0.465941</td>\n",
       "      <td>0.087780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s026</th>\n",
       "      <td>0.083103</td>\n",
       "      <td>0.258313</td>\n",
       "      <td>0.175209</td>\n",
       "      <td>0.079697</td>\n",
       "      <td>0.142671</td>\n",
       "      <td>0.062974</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>0.156128</td>\n",
       "      <td>0.075069</td>\n",
       "      <td>0.087127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088979</td>\n",
       "      <td>0.116312</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>0.078402</td>\n",
       "      <td>0.178514</td>\n",
       "      <td>0.100112</td>\n",
       "      <td>0.106668</td>\n",
       "      <td>0.305662</td>\n",
       "      <td>0.198994</td>\n",
       "      <td>0.094150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s027</th>\n",
       "      <td>0.098920</td>\n",
       "      <td>0.261244</td>\n",
       "      <td>0.162324</td>\n",
       "      <td>0.090637</td>\n",
       "      <td>0.223398</td>\n",
       "      <td>0.132761</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>0.113431</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.088723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114264</td>\n",
       "      <td>0.163497</td>\n",
       "      <td>0.049233</td>\n",
       "      <td>0.106220</td>\n",
       "      <td>0.172927</td>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.112365</td>\n",
       "      <td>0.317675</td>\n",
       "      <td>0.205309</td>\n",
       "      <td>0.080190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s028</th>\n",
       "      <td>0.071252</td>\n",
       "      <td>0.181910</td>\n",
       "      <td>0.110657</td>\n",
       "      <td>0.053342</td>\n",
       "      <td>0.129216</td>\n",
       "      <td>0.075874</td>\n",
       "      <td>0.064264</td>\n",
       "      <td>0.100064</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>0.059021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069513</td>\n",
       "      <td>0.110479</td>\n",
       "      <td>0.040966</td>\n",
       "      <td>0.063540</td>\n",
       "      <td>0.201888</td>\n",
       "      <td>0.138347</td>\n",
       "      <td>0.057618</td>\n",
       "      <td>0.254919</td>\n",
       "      <td>0.197301</td>\n",
       "      <td>0.059911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s029</th>\n",
       "      <td>0.086149</td>\n",
       "      <td>0.168584</td>\n",
       "      <td>0.082435</td>\n",
       "      <td>0.066363</td>\n",
       "      <td>0.146143</td>\n",
       "      <td>0.079780</td>\n",
       "      <td>0.054876</td>\n",
       "      <td>0.088441</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.077579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083664</td>\n",
       "      <td>0.110577</td>\n",
       "      <td>0.026913</td>\n",
       "      <td>0.104938</td>\n",
       "      <td>0.093911</td>\n",
       "      <td>-0.011026</td>\n",
       "      <td>0.096828</td>\n",
       "      <td>0.241510</td>\n",
       "      <td>0.144682</td>\n",
       "      <td>0.073887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s030</th>\n",
       "      <td>0.139943</td>\n",
       "      <td>0.275209</td>\n",
       "      <td>0.135266</td>\n",
       "      <td>0.117114</td>\n",
       "      <td>0.241703</td>\n",
       "      <td>0.124589</td>\n",
       "      <td>0.119833</td>\n",
       "      <td>0.276963</td>\n",
       "      <td>0.157131</td>\n",
       "      <td>0.143559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106096</td>\n",
       "      <td>0.242759</td>\n",
       "      <td>0.136663</td>\n",
       "      <td>0.104278</td>\n",
       "      <td>0.263769</td>\n",
       "      <td>0.159490</td>\n",
       "      <td>0.090913</td>\n",
       "      <td>0.389205</td>\n",
       "      <td>0.298292</td>\n",
       "      <td>0.088935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s031</th>\n",
       "      <td>0.102744</td>\n",
       "      <td>0.283371</td>\n",
       "      <td>0.180627</td>\n",
       "      <td>0.076643</td>\n",
       "      <td>0.195082</td>\n",
       "      <td>0.118439</td>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.187093</td>\n",
       "      <td>0.112787</td>\n",
       "      <td>0.074981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125108</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.084805</td>\n",
       "      <td>0.194338</td>\n",
       "      <td>0.109533</td>\n",
       "      <td>0.095127</td>\n",
       "      <td>0.364123</td>\n",
       "      <td>0.268997</td>\n",
       "      <td>0.072992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s032</th>\n",
       "      <td>0.106292</td>\n",
       "      <td>0.173698</td>\n",
       "      <td>0.067405</td>\n",
       "      <td>0.100846</td>\n",
       "      <td>0.194388</td>\n",
       "      <td>0.093543</td>\n",
       "      <td>0.088612</td>\n",
       "      <td>0.111285</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.086017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099593</td>\n",
       "      <td>0.141873</td>\n",
       "      <td>0.042279</td>\n",
       "      <td>0.079650</td>\n",
       "      <td>0.204170</td>\n",
       "      <td>0.124520</td>\n",
       "      <td>0.094842</td>\n",
       "      <td>0.250341</td>\n",
       "      <td>0.155499</td>\n",
       "      <td>0.088577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s033</th>\n",
       "      <td>0.093802</td>\n",
       "      <td>0.434662</td>\n",
       "      <td>0.340860</td>\n",
       "      <td>0.157469</td>\n",
       "      <td>0.167241</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.118349</td>\n",
       "      <td>0.307672</td>\n",
       "      <td>0.189323</td>\n",
       "      <td>0.113277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210091</td>\n",
       "      <td>0.249224</td>\n",
       "      <td>0.039133</td>\n",
       "      <td>0.109413</td>\n",
       "      <td>0.421057</td>\n",
       "      <td>0.311644</td>\n",
       "      <td>0.116598</td>\n",
       "      <td>0.441555</td>\n",
       "      <td>0.324958</td>\n",
       "      <td>0.102871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s034</th>\n",
       "      <td>0.092586</td>\n",
       "      <td>0.171587</td>\n",
       "      <td>0.079001</td>\n",
       "      <td>0.090049</td>\n",
       "      <td>0.125368</td>\n",
       "      <td>0.035319</td>\n",
       "      <td>0.065362</td>\n",
       "      <td>0.098744</td>\n",
       "      <td>0.033382</td>\n",
       "      <td>0.069771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103828</td>\n",
       "      <td>0.097451</td>\n",
       "      <td>-0.006377</td>\n",
       "      <td>0.115418</td>\n",
       "      <td>0.151479</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.094526</td>\n",
       "      <td>0.265094</td>\n",
       "      <td>0.170567</td>\n",
       "      <td>0.078707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s035</th>\n",
       "      <td>0.053406</td>\n",
       "      <td>0.278398</td>\n",
       "      <td>0.224992</td>\n",
       "      <td>0.076909</td>\n",
       "      <td>0.158555</td>\n",
       "      <td>0.081647</td>\n",
       "      <td>0.057120</td>\n",
       "      <td>0.155712</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076369</td>\n",
       "      <td>0.109565</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.075383</td>\n",
       "      <td>0.187947</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.304765</td>\n",
       "      <td>0.230076</td>\n",
       "      <td>0.071179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s036</th>\n",
       "      <td>0.046367</td>\n",
       "      <td>0.713184</td>\n",
       "      <td>0.666817</td>\n",
       "      <td>0.053015</td>\n",
       "      <td>0.264621</td>\n",
       "      <td>0.211606</td>\n",
       "      <td>0.045298</td>\n",
       "      <td>0.500703</td>\n",
       "      <td>0.455404</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.361387</td>\n",
       "      <td>0.304614</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>0.596812</td>\n",
       "      <td>0.557690</td>\n",
       "      <td>0.041112</td>\n",
       "      <td>0.861114</td>\n",
       "      <td>0.820002</td>\n",
       "      <td>0.048121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s037</th>\n",
       "      <td>0.107253</td>\n",
       "      <td>0.153223</td>\n",
       "      <td>0.045969</td>\n",
       "      <td>0.080795</td>\n",
       "      <td>0.153683</td>\n",
       "      <td>0.072888</td>\n",
       "      <td>0.065569</td>\n",
       "      <td>0.093215</td>\n",
       "      <td>0.027646</td>\n",
       "      <td>0.091388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100327</td>\n",
       "      <td>0.119873</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.084280</td>\n",
       "      <td>0.178222</td>\n",
       "      <td>0.093942</td>\n",
       "      <td>0.114880</td>\n",
       "      <td>0.261359</td>\n",
       "      <td>0.146479</td>\n",
       "      <td>0.102549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s038</th>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.343160</td>\n",
       "      <td>0.253620</td>\n",
       "      <td>0.085868</td>\n",
       "      <td>0.104937</td>\n",
       "      <td>0.019069</td>\n",
       "      <td>0.066784</td>\n",
       "      <td>0.138481</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>0.073896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112545</td>\n",
       "      <td>0.140352</td>\n",
       "      <td>0.027807</td>\n",
       "      <td>0.065569</td>\n",
       "      <td>0.205060</td>\n",
       "      <td>0.139491</td>\n",
       "      <td>0.094894</td>\n",
       "      <td>0.381904</td>\n",
       "      <td>0.287010</td>\n",
       "      <td>0.079855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s039</th>\n",
       "      <td>0.080426</td>\n",
       "      <td>0.220070</td>\n",
       "      <td>0.139645</td>\n",
       "      <td>0.089835</td>\n",
       "      <td>0.160651</td>\n",
       "      <td>0.070816</td>\n",
       "      <td>0.077974</td>\n",
       "      <td>0.168084</td>\n",
       "      <td>0.090110</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098837</td>\n",
       "      <td>0.139102</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.086395</td>\n",
       "      <td>0.221530</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.086296</td>\n",
       "      <td>0.227535</td>\n",
       "      <td>0.141239</td>\n",
       "      <td>0.095358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s040</th>\n",
       "      <td>0.111795</td>\n",
       "      <td>0.418321</td>\n",
       "      <td>0.306526</td>\n",
       "      <td>0.122487</td>\n",
       "      <td>0.156404</td>\n",
       "      <td>0.033916</td>\n",
       "      <td>0.118440</td>\n",
       "      <td>0.209128</td>\n",
       "      <td>0.090688</td>\n",
       "      <td>0.135645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179581</td>\n",
       "      <td>0.193874</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.134806</td>\n",
       "      <td>0.222849</td>\n",
       "      <td>0.088043</td>\n",
       "      <td>0.122312</td>\n",
       "      <td>0.427761</td>\n",
       "      <td>0.305449</td>\n",
       "      <td>0.110760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s041</th>\n",
       "      <td>0.174045</td>\n",
       "      <td>0.271722</td>\n",
       "      <td>0.097677</td>\n",
       "      <td>0.127022</td>\n",
       "      <td>0.213269</td>\n",
       "      <td>0.086247</td>\n",
       "      <td>0.126011</td>\n",
       "      <td>0.165963</td>\n",
       "      <td>0.039952</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173207</td>\n",
       "      <td>0.147185</td>\n",
       "      <td>-0.026022</td>\n",
       "      <td>0.129762</td>\n",
       "      <td>0.197948</td>\n",
       "      <td>0.068186</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>0.328032</td>\n",
       "      <td>0.175614</td>\n",
       "      <td>0.139194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s042</th>\n",
       "      <td>0.102485</td>\n",
       "      <td>0.307059</td>\n",
       "      <td>0.204574</td>\n",
       "      <td>0.058812</td>\n",
       "      <td>0.153221</td>\n",
       "      <td>0.094408</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.179472</td>\n",
       "      <td>0.112278</td>\n",
       "      <td>0.074015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>0.183869</td>\n",
       "      <td>0.109878</td>\n",
       "      <td>0.136343</td>\n",
       "      <td>0.119053</td>\n",
       "      <td>-0.017291</td>\n",
       "      <td>0.126178</td>\n",
       "      <td>0.319862</td>\n",
       "      <td>0.193684</td>\n",
       "      <td>0.121442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s043</th>\n",
       "      <td>0.060295</td>\n",
       "      <td>0.415829</td>\n",
       "      <td>0.355534</td>\n",
       "      <td>0.070842</td>\n",
       "      <td>0.301946</td>\n",
       "      <td>0.231104</td>\n",
       "      <td>0.063328</td>\n",
       "      <td>0.233215</td>\n",
       "      <td>0.169887</td>\n",
       "      <td>0.083608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104249</td>\n",
       "      <td>0.244769</td>\n",
       "      <td>0.140520</td>\n",
       "      <td>0.054197</td>\n",
       "      <td>0.310245</td>\n",
       "      <td>0.256047</td>\n",
       "      <td>0.052379</td>\n",
       "      <td>0.341390</td>\n",
       "      <td>0.289011</td>\n",
       "      <td>0.046771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s044</th>\n",
       "      <td>0.077319</td>\n",
       "      <td>0.326764</td>\n",
       "      <td>0.249445</td>\n",
       "      <td>0.059390</td>\n",
       "      <td>0.134183</td>\n",
       "      <td>0.074793</td>\n",
       "      <td>0.055647</td>\n",
       "      <td>0.193332</td>\n",
       "      <td>0.137685</td>\n",
       "      <td>0.053232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086312</td>\n",
       "      <td>0.187196</td>\n",
       "      <td>0.100885</td>\n",
       "      <td>0.061402</td>\n",
       "      <td>0.215574</td>\n",
       "      <td>0.154172</td>\n",
       "      <td>0.082380</td>\n",
       "      <td>0.284383</td>\n",
       "      <td>0.202003</td>\n",
       "      <td>0.069622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s046</th>\n",
       "      <td>0.107903</td>\n",
       "      <td>0.411358</td>\n",
       "      <td>0.303455</td>\n",
       "      <td>0.088258</td>\n",
       "      <td>0.190271</td>\n",
       "      <td>0.102013</td>\n",
       "      <td>0.068619</td>\n",
       "      <td>0.248335</td>\n",
       "      <td>0.179716</td>\n",
       "      <td>0.082987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110025</td>\n",
       "      <td>0.154454</td>\n",
       "      <td>0.044429</td>\n",
       "      <td>0.104642</td>\n",
       "      <td>0.245357</td>\n",
       "      <td>0.140715</td>\n",
       "      <td>0.109707</td>\n",
       "      <td>0.302893</td>\n",
       "      <td>0.193187</td>\n",
       "      <td>0.088138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s047</th>\n",
       "      <td>0.086283</td>\n",
       "      <td>0.291124</td>\n",
       "      <td>0.204841</td>\n",
       "      <td>0.083445</td>\n",
       "      <td>0.380895</td>\n",
       "      <td>0.297450</td>\n",
       "      <td>0.074024</td>\n",
       "      <td>0.169497</td>\n",
       "      <td>0.095473</td>\n",
       "      <td>0.075369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084238</td>\n",
       "      <td>0.157661</td>\n",
       "      <td>0.073423</td>\n",
       "      <td>0.101031</td>\n",
       "      <td>0.272264</td>\n",
       "      <td>0.171232</td>\n",
       "      <td>0.112884</td>\n",
       "      <td>0.308844</td>\n",
       "      <td>0.195960</td>\n",
       "      <td>0.097515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s048</th>\n",
       "      <td>0.098574</td>\n",
       "      <td>0.184464</td>\n",
       "      <td>0.085890</td>\n",
       "      <td>0.089793</td>\n",
       "      <td>0.093280</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.072284</td>\n",
       "      <td>0.116333</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.106091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096081</td>\n",
       "      <td>0.118139</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.086969</td>\n",
       "      <td>0.156660</td>\n",
       "      <td>0.069690</td>\n",
       "      <td>0.094111</td>\n",
       "      <td>0.249947</td>\n",
       "      <td>0.155836</td>\n",
       "      <td>0.096596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s049</th>\n",
       "      <td>0.081739</td>\n",
       "      <td>0.553767</td>\n",
       "      <td>0.472028</td>\n",
       "      <td>0.124781</td>\n",
       "      <td>0.249838</td>\n",
       "      <td>0.125056</td>\n",
       "      <td>0.072931</td>\n",
       "      <td>0.356760</td>\n",
       "      <td>0.283829</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152279</td>\n",
       "      <td>0.310451</td>\n",
       "      <td>0.158173</td>\n",
       "      <td>0.073960</td>\n",
       "      <td>0.447560</td>\n",
       "      <td>0.373599</td>\n",
       "      <td>0.076292</td>\n",
       "      <td>0.767430</td>\n",
       "      <td>0.691138</td>\n",
       "      <td>0.076478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s050</th>\n",
       "      <td>0.084314</td>\n",
       "      <td>0.248130</td>\n",
       "      <td>0.163816</td>\n",
       "      <td>0.062744</td>\n",
       "      <td>0.173590</td>\n",
       "      <td>0.110847</td>\n",
       "      <td>0.072154</td>\n",
       "      <td>0.170373</td>\n",
       "      <td>0.098218</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111869</td>\n",
       "      <td>0.122196</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.086736</td>\n",
       "      <td>0.214202</td>\n",
       "      <td>0.127466</td>\n",
       "      <td>0.085796</td>\n",
       "      <td>0.280488</td>\n",
       "      <td>0.194691</td>\n",
       "      <td>0.086331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s051</th>\n",
       "      <td>0.102949</td>\n",
       "      <td>0.179758</td>\n",
       "      <td>0.076809</td>\n",
       "      <td>0.071980</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.030294</td>\n",
       "      <td>0.075004</td>\n",
       "      <td>0.100971</td>\n",
       "      <td>0.025967</td>\n",
       "      <td>0.085157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>0.134353</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>0.097739</td>\n",
       "      <td>0.118610</td>\n",
       "      <td>0.020871</td>\n",
       "      <td>0.081002</td>\n",
       "      <td>0.212542</td>\n",
       "      <td>0.131540</td>\n",
       "      <td>0.059906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s052</th>\n",
       "      <td>0.057601</td>\n",
       "      <td>0.583033</td>\n",
       "      <td>0.525432</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.060924</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>0.113019</td>\n",
       "      <td>0.115025</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.078477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095944</td>\n",
       "      <td>0.163985</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.096798</td>\n",
       "      <td>0.066812</td>\n",
       "      <td>-0.029986</td>\n",
       "      <td>0.109137</td>\n",
       "      <td>0.446624</td>\n",
       "      <td>0.337488</td>\n",
       "      <td>0.070540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s053</th>\n",
       "      <td>0.101145</td>\n",
       "      <td>0.184789</td>\n",
       "      <td>0.083643</td>\n",
       "      <td>0.056687</td>\n",
       "      <td>0.095649</td>\n",
       "      <td>0.038962</td>\n",
       "      <td>0.095432</td>\n",
       "      <td>0.096936</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.054212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109866</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.032095</td>\n",
       "      <td>0.113979</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>-0.026950</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>0.227387</td>\n",
       "      <td>0.128192</td>\n",
       "      <td>0.093296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s054</th>\n",
       "      <td>0.088336</td>\n",
       "      <td>0.298038</td>\n",
       "      <td>0.209703</td>\n",
       "      <td>0.079005</td>\n",
       "      <td>0.120044</td>\n",
       "      <td>0.041039</td>\n",
       "      <td>0.084715</td>\n",
       "      <td>0.108656</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.095865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102321</td>\n",
       "      <td>0.123531</td>\n",
       "      <td>0.021210</td>\n",
       "      <td>0.107646</td>\n",
       "      <td>0.145709</td>\n",
       "      <td>0.038064</td>\n",
       "      <td>0.107922</td>\n",
       "      <td>0.279601</td>\n",
       "      <td>0.171679</td>\n",
       "      <td>0.095386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s055</th>\n",
       "      <td>0.094679</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>0.038784</td>\n",
       "      <td>0.106532</td>\n",
       "      <td>0.118625</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.086479</td>\n",
       "      <td>0.082276</td>\n",
       "      <td>-0.004203</td>\n",
       "      <td>0.116801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090208</td>\n",
       "      <td>0.069409</td>\n",
       "      <td>-0.020799</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>0.176760</td>\n",
       "      <td>0.112876</td>\n",
       "      <td>0.101798</td>\n",
       "      <td>0.149550</td>\n",
       "      <td>0.047752</td>\n",
       "      <td>0.118211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s056</th>\n",
       "      <td>0.094418</td>\n",
       "      <td>0.168167</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>0.135758</td>\n",
       "      <td>0.053289</td>\n",
       "      <td>0.092614</td>\n",
       "      <td>0.089619</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>0.090461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101621</td>\n",
       "      <td>0.118126</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.065504</td>\n",
       "      <td>0.167630</td>\n",
       "      <td>0.102126</td>\n",
       "      <td>0.109050</td>\n",
       "      <td>0.156654</td>\n",
       "      <td>0.047603</td>\n",
       "      <td>0.119984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s057</th>\n",
       "      <td>0.092038</td>\n",
       "      <td>0.139243</td>\n",
       "      <td>0.047204</td>\n",
       "      <td>0.078932</td>\n",
       "      <td>0.118983</td>\n",
       "      <td>0.040051</td>\n",
       "      <td>0.077480</td>\n",
       "      <td>0.087617</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>0.073077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088672</td>\n",
       "      <td>0.104452</td>\n",
       "      <td>0.015780</td>\n",
       "      <td>0.069294</td>\n",
       "      <td>0.151573</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.105666</td>\n",
       "      <td>0.262381</td>\n",
       "      <td>0.156716</td>\n",
       "      <td>0.112769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         H.period  DD.period.t  UD.period.t       H.t    DD.t.i    UD.t.i  \\\n",
       "subject                                                                     \n",
       "s002     0.106958     0.169556     0.062598  0.086247  0.150193  0.063946   \n",
       "s003     0.157293     0.169161     0.011867  0.134296  0.155552  0.021256   \n",
       "s004     0.103745     0.201064     0.097319  0.104109  0.148142  0.044033   \n",
       "s005     0.081963     0.278241     0.196278  0.116951  0.227286  0.110334   \n",
       "s007     0.095211     0.176463     0.081252  0.074890  0.120669  0.045778   \n",
       "s008     0.087904     0.207432     0.119528  0.083517  0.114949  0.031433   \n",
       "s010     0.089034     0.149080     0.060046  0.067136  0.147262  0.080126   \n",
       "s011     0.081427     0.165664     0.084237  0.118299  0.140476  0.022176   \n",
       "s012     0.140250     0.185625     0.045376  0.124888  0.149185  0.024297   \n",
       "s013     0.080338     0.128903     0.048564  0.071634  0.116411  0.044776   \n",
       "s015     0.078122     0.168027     0.089905  0.075487  0.104308  0.028820   \n",
       "s016     0.104281     0.435364     0.331084  0.066853  0.245018  0.178165   \n",
       "s017     0.071280     0.186818     0.115538  0.051763  0.121061  0.069298   \n",
       "s018     0.091629     0.161282     0.069653  0.090197  0.146472  0.056275   \n",
       "s019     0.077281     0.298299     0.221019  0.087500  0.274091  0.186591   \n",
       "s020     0.109741     0.207484     0.097743  0.093292  0.159533  0.066241   \n",
       "s021     0.099546     0.219191     0.119645  0.086131  0.203666  0.117535   \n",
       "s022     0.054491     0.515802     0.461312  0.052300  0.374969  0.322669   \n",
       "s024     0.073995     0.207199     0.133205  0.053672  0.171567  0.117895   \n",
       "s025     0.110121     0.209256     0.099134  0.071676  0.145707  0.074031   \n",
       "s026     0.083103     0.258313     0.175209  0.079697  0.142671  0.062974   \n",
       "s027     0.098920     0.261244     0.162324  0.090637  0.223398  0.132761   \n",
       "s028     0.071252     0.181910     0.110657  0.053342  0.129216  0.075874   \n",
       "s029     0.086149     0.168584     0.082435  0.066363  0.146143  0.079780   \n",
       "s030     0.139943     0.275209     0.135266  0.117114  0.241703  0.124589   \n",
       "s031     0.102744     0.283371     0.180627  0.076643  0.195082  0.118439   \n",
       "s032     0.106292     0.173698     0.067405  0.100846  0.194388  0.093543   \n",
       "s033     0.093802     0.434662     0.340860  0.157469  0.167241  0.009772   \n",
       "s034     0.092586     0.171587     0.079001  0.090049  0.125368  0.035319   \n",
       "s035     0.053406     0.278398     0.224992  0.076909  0.158555  0.081647   \n",
       "s036     0.046367     0.713184     0.666817  0.053015  0.264621  0.211606   \n",
       "s037     0.107253     0.153223     0.045969  0.080795  0.153683  0.072888   \n",
       "s038     0.089541     0.343160     0.253620  0.085868  0.104937  0.019069   \n",
       "s039     0.080426     0.220070     0.139645  0.089835  0.160651  0.070816   \n",
       "s040     0.111795     0.418321     0.306526  0.122487  0.156404  0.033916   \n",
       "s041     0.174045     0.271722     0.097677  0.127022  0.213269  0.086247   \n",
       "s042     0.102485     0.307059     0.204574  0.058812  0.153221  0.094408   \n",
       "s043     0.060295     0.415829     0.355534  0.070842  0.301946  0.231104   \n",
       "s044     0.077319     0.326764     0.249445  0.059390  0.134183  0.074793   \n",
       "s046     0.107903     0.411358     0.303455  0.088258  0.190271  0.102013   \n",
       "s047     0.086283     0.291124     0.204841  0.083445  0.380895  0.297450   \n",
       "s048     0.098574     0.184464     0.085890  0.089793  0.093280  0.003487   \n",
       "s049     0.081739     0.553767     0.472028  0.124781  0.249838  0.125056   \n",
       "s050     0.084314     0.248130     0.163816  0.062744  0.173590  0.110847   \n",
       "s051     0.102949     0.179758     0.076809  0.071980  0.102273  0.030294   \n",
       "s052     0.057601     0.583033     0.525432  0.079479  0.060924 -0.018555   \n",
       "s053     0.101145     0.184789     0.083643  0.056687  0.095649  0.038962   \n",
       "s054     0.088336     0.298038     0.209703  0.079005  0.120044  0.041039   \n",
       "s055     0.094679     0.133463     0.038784  0.106532  0.118625  0.012093   \n",
       "s056     0.094418     0.168167     0.073750  0.082469  0.135758  0.053289   \n",
       "s057     0.092038     0.139243     0.047204  0.078932  0.118983  0.040051   \n",
       "\n",
       "              H.i    DD.i.e    UD.i.e       H.e  ...       H.a    DD.a.n  \\\n",
       "subject                                          ...                       \n",
       "s002     0.077409  0.126418  0.049009  0.089132  ...  0.117492  0.121199   \n",
       "s003     0.127763  0.143294  0.015531  0.152307  ...  0.143438  0.122862   \n",
       "s004     0.106150  0.126316  0.020166  0.080580  ...  0.129352  0.117051   \n",
       "s005     0.089127  0.194292  0.105166  0.113709  ...  0.131529  0.185614   \n",
       "s007     0.076754  0.104828  0.028075  0.089969  ...  0.103193  0.117067   \n",
       "s008     0.078263  0.113117  0.034854  0.092462  ...  0.113499  0.110634   \n",
       "s010     0.081407  0.119041  0.037635  0.067630  ...  0.061829  0.118330   \n",
       "s011     0.092703  0.143644  0.050940  0.110688  ...  0.126625  0.105366   \n",
       "s012     0.133069  0.144739  0.011670  0.127673  ...  0.162381  0.142180   \n",
       "s013     0.088232  0.100223  0.011990  0.061283  ...  0.097836  0.103268   \n",
       "s015     0.070376  0.077613  0.007237  0.078238  ...  0.086392  0.087962   \n",
       "s016     0.083918  0.320703  0.236785  0.094588  ...  0.117256  0.293637   \n",
       "s017     0.049009  0.097323  0.048314  0.060762  ...  0.071189  0.080817   \n",
       "s018     0.075392  0.141473  0.066081  0.081294  ...  0.113673  0.130511   \n",
       "s019     0.059477  0.095274  0.035797  0.091478  ...  0.112876  0.183659   \n",
       "s020     0.112904  0.152390  0.039485  0.098645  ...  0.131727  0.179090   \n",
       "s021     0.090883  0.155242  0.064358  0.076037  ...  0.067404  0.168593   \n",
       "s022     0.047068  0.285859  0.238791  0.088721  ...  0.094672  0.207343   \n",
       "s024     0.049126  0.140358  0.091232  0.059769  ...  0.079150  0.132264   \n",
       "s025     0.065531  0.126289  0.060758  0.078929  ...  0.068310  0.111173   \n",
       "s026     0.081059  0.156128  0.075069  0.087127  ...  0.088979  0.116312   \n",
       "s027     0.110497  0.113431  0.002934  0.088723  ...  0.114264  0.163497   \n",
       "s028     0.064264  0.100064  0.035801  0.059021  ...  0.069513  0.110479   \n",
       "s029     0.054876  0.088441  0.033565  0.077579  ...  0.083664  0.110577   \n",
       "s030     0.119833  0.276963  0.157131  0.143559  ...  0.106096  0.242759   \n",
       "s031     0.074306  0.187093  0.112787  0.074981  ...  0.125108  0.151679   \n",
       "s032     0.088612  0.111285  0.022673  0.086017  ...  0.099593  0.141873   \n",
       "s033     0.118349  0.307672  0.189323  0.113277  ...  0.210091  0.249224   \n",
       "s034     0.065362  0.098744  0.033382  0.069771  ...  0.103828  0.097451   \n",
       "s035     0.057120  0.155712  0.098592  0.093775  ...  0.076369  0.109565   \n",
       "s036     0.045298  0.500703  0.455404  0.050795  ...  0.056773  0.361387   \n",
       "s037     0.065569  0.093215  0.027646  0.091388  ...  0.100327  0.119873   \n",
       "s038     0.066784  0.138481  0.071696  0.073896  ...  0.112545  0.140352   \n",
       "s039     0.077974  0.168084  0.090110  0.081258  ...  0.098837  0.139102   \n",
       "s040     0.118440  0.209128  0.090688  0.135645  ...  0.179581  0.193874   \n",
       "s041     0.126011  0.165963  0.039952  0.150943  ...  0.173207  0.147185   \n",
       "s042     0.067195  0.179472  0.112278  0.074015  ...  0.073992  0.183869   \n",
       "s043     0.063328  0.233215  0.169887  0.083608  ...  0.104249  0.244769   \n",
       "s044     0.055647  0.193332  0.137685  0.053232  ...  0.086312  0.187196   \n",
       "s046     0.068619  0.248335  0.179716  0.082987  ...  0.110025  0.154454   \n",
       "s047     0.074024  0.169497  0.095473  0.075369  ...  0.084238  0.157661   \n",
       "s048     0.072284  0.116333  0.044050  0.106091  ...  0.096081  0.118139   \n",
       "s049     0.072931  0.356760  0.283829  0.124595  ...  0.152279  0.310451   \n",
       "s050     0.072154  0.170373  0.098218  0.080460  ...  0.111869  0.122196   \n",
       "s051     0.075004  0.100971  0.025967  0.085157  ...  0.082949  0.134353   \n",
       "s052     0.113019  0.115025  0.002005  0.078477  ...  0.095944  0.163985   \n",
       "s053     0.095432  0.096936  0.001504  0.054212  ...  0.109866  0.077771   \n",
       "s054     0.084715  0.108656  0.023941  0.095865  ...  0.102321  0.123531   \n",
       "s055     0.086479  0.082276 -0.004203  0.116801  ...  0.090208  0.069409   \n",
       "s056     0.092614  0.089619 -0.002995  0.090461  ...  0.101621  0.118126   \n",
       "s057     0.077480  0.087617  0.010137  0.073077  ...  0.088672  0.104452   \n",
       "\n",
       "           UD.a.n       H.n    DD.n.l    UD.n.l       H.l  DD.l.Return  \\\n",
       "subject                                                                  \n",
       "s002     0.003707  0.084263  0.214241  0.129977  0.096058     0.248565   \n",
       "s003    -0.020576  0.110990  0.152210  0.041221  0.103004     0.268717   \n",
       "s004    -0.012301  0.085273  0.154218  0.068945  0.093692     0.226031   \n",
       "s005     0.054085  0.085989  0.250916  0.164927  0.087597     0.406607   \n",
       "s007     0.013874  0.125255  0.112926 -0.012329  0.096714     0.239116   \n",
       "s008    -0.002865  0.096973  0.119943  0.022970  0.093137     0.225950   \n",
       "s010     0.056501  0.080376  0.225239  0.144863  0.079028     0.214162   \n",
       "s011    -0.021258  0.119474  0.094745 -0.024730  0.112906     0.149493   \n",
       "s012    -0.020200  0.137033  0.130215 -0.006819  0.148068     0.304430   \n",
       "s013     0.005431  0.060277  0.143281  0.083004  0.074938     0.227142   \n",
       "s015     0.001570  0.075132  0.128458  0.053326  0.075000     0.200053   \n",
       "s016     0.176380  0.100993  0.302622  0.201629  0.100716     0.410868   \n",
       "s017     0.009628  0.057405  0.167068  0.109663  0.070389     0.211661   \n",
       "s018     0.016838  0.125686  0.085284 -0.040403  0.120233     0.304630   \n",
       "s019     0.070782  0.069474  0.275717  0.206242  0.072334     0.521120   \n",
       "s020     0.047362  0.119103  0.157470  0.038366  0.136530     0.251457   \n",
       "s021     0.101190  0.081709  0.217302  0.135593  0.095730     0.334604   \n",
       "s022     0.112672  0.053791  0.385210  0.331419  0.049452     0.590261   \n",
       "s024     0.053114  0.056814  0.244982  0.188168  0.071531     0.308494   \n",
       "s025     0.042863  0.076744  0.184639  0.107896  0.092383     0.558323   \n",
       "s026     0.027333  0.078402  0.178514  0.100112  0.106668     0.305662   \n",
       "s027     0.049233  0.106220  0.172927  0.066707  0.112365     0.317675   \n",
       "s028     0.040966  0.063540  0.201888  0.138347  0.057618     0.254919   \n",
       "s029     0.026913  0.104938  0.093911 -0.011026  0.096828     0.241510   \n",
       "s030     0.136663  0.104278  0.263769  0.159490  0.090913     0.389205   \n",
       "s031     0.026571  0.084805  0.194338  0.109533  0.095127     0.364123   \n",
       "s032     0.042279  0.079650  0.204170  0.124520  0.094842     0.250341   \n",
       "s033     0.039133  0.109413  0.421057  0.311644  0.116598     0.441555   \n",
       "s034    -0.006377  0.115418  0.151479  0.036061  0.094526     0.265094   \n",
       "s035     0.033195  0.075383  0.187947  0.112564  0.074689     0.304765   \n",
       "s036     0.304614  0.039122  0.596812  0.557690  0.041112     0.861114   \n",
       "s037     0.019547  0.084280  0.178222  0.093942  0.114880     0.261359   \n",
       "s038     0.027807  0.065569  0.205060  0.139491  0.094894     0.381904   \n",
       "s039     0.040266  0.086395  0.221530  0.135135  0.086296     0.227535   \n",
       "s040     0.014293  0.134806  0.222849  0.088043  0.122312     0.427761   \n",
       "s041    -0.026022  0.129762  0.197948  0.068186  0.152418     0.328032   \n",
       "s042     0.109878  0.136343  0.119053 -0.017291  0.126178     0.319862   \n",
       "s043     0.140520  0.054197  0.310245  0.256047  0.052379     0.341390   \n",
       "s044     0.100885  0.061402  0.215574  0.154172  0.082380     0.284383   \n",
       "s046     0.044429  0.104642  0.245357  0.140715  0.109707     0.302893   \n",
       "s047     0.073423  0.101031  0.272264  0.171232  0.112884     0.308844   \n",
       "s048     0.022058  0.086969  0.156660  0.069690  0.094111     0.249947   \n",
       "s049     0.158173  0.073960  0.447560  0.373599  0.076292     0.767430   \n",
       "s050     0.010327  0.086736  0.214202  0.127466  0.085796     0.280488   \n",
       "s051     0.051404  0.097739  0.118610  0.020871  0.081002     0.212542   \n",
       "s052     0.068041  0.096798  0.066812 -0.029986  0.109137     0.446624   \n",
       "s053    -0.032095  0.113979  0.087029 -0.026950  0.099195     0.227387   \n",
       "s054     0.021210  0.107646  0.145709  0.038064  0.107922     0.279601   \n",
       "s055    -0.020799  0.063884  0.176760  0.112876  0.101798     0.149550   \n",
       "s056     0.016505  0.065504  0.167630  0.102126  0.109050     0.156654   \n",
       "s057     0.015780  0.069294  0.151573  0.082278  0.105666     0.262381   \n",
       "\n",
       "         UD.l.Return  H.Return  \n",
       "subject                         \n",
       "s002        0.152508  0.082700  \n",
       "s003        0.165713  0.099209  \n",
       "s004        0.132339  0.075529  \n",
       "s005        0.319010  0.092090  \n",
       "s007        0.142402  0.083882  \n",
       "s008        0.132813  0.100621  \n",
       "s010        0.135134  0.078380  \n",
       "s011        0.036587  0.125489  \n",
       "s012        0.156362  0.140239  \n",
       "s013        0.152204  0.085247  \n",
       "s015        0.125054  0.072395  \n",
       "s016        0.310152  0.093568  \n",
       "s017        0.141272  0.061676  \n",
       "s018        0.184397  0.077346  \n",
       "s019        0.448786  0.095091  \n",
       "s020        0.114927  0.102723  \n",
       "s021        0.238874  0.084151  \n",
       "s022        0.540809  0.056212  \n",
       "s024        0.236963  0.069065  \n",
       "s025        0.465941  0.087780  \n",
       "s026        0.198994  0.094150  \n",
       "s027        0.205309  0.080190  \n",
       "s028        0.197301  0.059911  \n",
       "s029        0.144682  0.073887  \n",
       "s030        0.298292  0.088935  \n",
       "s031        0.268997  0.072992  \n",
       "s032        0.155499  0.088577  \n",
       "s033        0.324958  0.102871  \n",
       "s034        0.170567  0.078707  \n",
       "s035        0.230076  0.071179  \n",
       "s036        0.820002  0.048121  \n",
       "s037        0.146479  0.102549  \n",
       "s038        0.287010  0.079855  \n",
       "s039        0.141239  0.095358  \n",
       "s040        0.305449  0.110760  \n",
       "s041        0.175614  0.139194  \n",
       "s042        0.193684  0.121442  \n",
       "s043        0.289011  0.046771  \n",
       "s044        0.202003  0.069622  \n",
       "s046        0.193187  0.088138  \n",
       "s047        0.195960  0.097515  \n",
       "s048        0.155836  0.096596  \n",
       "s049        0.691138  0.076478  \n",
       "s050        0.194691  0.086331  \n",
       "s051        0.131540  0.059906  \n",
       "s052        0.337488  0.070540  \n",
       "s053        0.128192  0.093296  \n",
       "s054        0.171679  0.095386  \n",
       "s055        0.047752  0.118211  \n",
       "s056        0.047603  0.119984  \n",
       "s057        0.156716  0.112769  \n",
       "\n",
       "[51 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.groupby(\"subject\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "27d0b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if mean+std<value or mean-std>value -> delete\n",
    "\n",
    "def remove_outliers(data: pd.DataFrame,std_multiplier: float):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key,person_data in data.groupby(\"subject\"):\n",
    "        person_std = person_data.std(numeric_only=True)\n",
    "        person_mean = person_data.mean(numeric_only=True)\n",
    "        numeric_data = person_data.select_dtypes(include=\"number\")\n",
    "\n",
    "        is_high = numeric_data>(person_mean+std_multiplier*person_std)\n",
    "        is_low = numeric_data<(person_mean-std_multiplier*person_std)\n",
    "\n",
    "        outliers = is_high | is_low\n",
    "\n",
    "        outliers_df = numeric_data[outliers.any(axis=1)]\n",
    "        clean_df = person_data[~outliers.any(axis=1)]\n",
    "        df_out = pd.concat([df_out,clean_df],ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa10d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = remove_outliers(data1,2.7)#.to_csv(\"cleaned_keystroke_data2point7std.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a08654b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['output'] = (dataset['subject'] == 's002').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "55a761fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "32947eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>H.e</th>\n",
       "      <th>...</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0966</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.2868</td>\n",
       "      <td>0.1986</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>-0.0301</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>-0.1180</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.2599</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.1839</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.2643</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14596</th>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>-0.0266</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>-0.0146</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14597</th>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>-0.0188</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14598</th>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>-0.0280</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>-0.0496</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.1198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14599</th>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14600</th>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14601 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i     H.i  \\\n",
       "0        0.0966       0.1797       0.0831  0.0771  0.1296  0.0525  0.0839   \n",
       "1        0.1093       0.1807       0.0714  0.0731  0.1457  0.0726  0.0766   \n",
       "2        0.0887       0.1660       0.0773  0.0876  0.1560  0.0684  0.0839   \n",
       "3        0.0911       0.1525       0.0614  0.0824  0.1516  0.0692  0.0731   \n",
       "4        0.1270       0.1839       0.0569  0.0911  0.1381  0.0470  0.0895   \n",
       "...         ...          ...          ...     ...     ...     ...     ...   \n",
       "14596    0.0665       0.0678       0.0013  0.0902  0.1601  0.0699  0.0515   \n",
       "14597    0.0884       0.0685      -0.0199  0.1095  0.1290  0.0195  0.0945   \n",
       "14598    0.0655       0.0630      -0.0025  0.0910  0.1148  0.0238  0.0916   \n",
       "14599    0.0939       0.1189       0.0250  0.1008  0.1122  0.0114  0.0721   \n",
       "14600    0.0923       0.1294       0.0371  0.0913  0.0990  0.0077  0.0992   \n",
       "\n",
       "       DD.i.e  UD.i.e     H.e  ...  DD.a.n  UD.a.n     H.n  DD.n.l  UD.n.l  \\\n",
       "0      0.1425  0.0586  0.0755  ...  0.1403  0.0141  0.0787  0.2138  0.1351   \n",
       "1      0.1241  0.0475  0.0813  ...  0.1162 -0.0301  0.1207  0.2281  0.1074   \n",
       "2      0.1386  0.0547  0.0692  ...  0.0502 -0.1180  0.0866  0.4062  0.3196   \n",
       "3      0.1391  0.0660  0.0832  ...  0.1492  0.0027  0.0758  0.2201  0.1443   \n",
       "4      0.1774  0.0879  0.0739  ...  0.1521  0.0183  0.0774  0.1954  0.1180   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "14596  0.0391 -0.0124  0.0794  ...  0.0765 -0.0266  0.0768  0.0622 -0.0146   \n",
       "14597  0.0757 -0.0188  0.1328  ...  0.1383  0.0164  0.0820  0.1329  0.0509   \n",
       "14598  0.0636 -0.0280  0.1256  ...  0.0512 -0.0496  0.1037  0.0868 -0.0169   \n",
       "14599  0.0462 -0.0259  0.0903  ...  0.1169  0.0256  0.0689  0.1311  0.0622   \n",
       "14600  0.0897 -0.0095  0.1016  ...  0.0821 -0.0061  0.0576  0.0697  0.0121   \n",
       "\n",
       "          H.l  DD.l.Return  UD.l.Return  H.Return  output  \n",
       "0      0.0882       0.2868       0.1986    0.0634       1  \n",
       "1      0.1204       0.3187       0.1983    0.0866       1  \n",
       "2      0.0927       0.2897       0.1970    0.0792       1  \n",
       "3      0.0742       0.2599       0.1857    0.0779       1  \n",
       "4      0.0942       0.2643       0.1701    0.0631       1  \n",
       "...       ...          ...          ...       ...     ...  \n",
       "14596  0.1051       0.2047       0.0996    0.1105       0  \n",
       "14597  0.1005       0.2054       0.1049    0.1047       0  \n",
       "14598  0.1445       0.2206       0.0761    0.1198       0  \n",
       "14599  0.1034       0.2017       0.0983    0.0905       0  \n",
       "14600  0.0979       0.1917       0.0938    0.0931       0  \n",
       "\n",
       "[14601 rows x 32 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92a2b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ff6e0f1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[135]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_df,test_df = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/machine-learning/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:208\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m to_ignore += [\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcls\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    206\u001b[39m params = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params.arguments.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__qualname__\u001b[39;49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/machine-learning/lib/python3.14/site-packages/sklearn/utils/_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got 0 instead."
     ]
    }
   ],
   "source": [
    "train_df,test_df = train_test_split(dataset,test_size=0,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f3d45d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>H.e</th>\n",
       "      <th>...</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.2541</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3239</td>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>0.1868</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.3295</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>-0.0847</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>-0.0233</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.4830</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>0.3197</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.5220</td>\n",
       "      <td>0.4433</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.4331</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14600 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i     H.i  \\\n",
       "9355     0.0952       0.3704       0.2752  0.1018  0.1374  0.0356  0.0602   \n",
       "3013     0.0689       0.1374       0.0685  0.0636  0.0969  0.0333  0.0729   \n",
       "1475     0.1037       0.1997       0.0960  0.1017  0.0998 -0.0019  0.1004   \n",
       "7420     0.1008       0.3650       0.2642  0.1002  0.1622  0.0620  0.0805   \n",
       "6903     0.1460       0.2541       0.1081  0.1227  0.2328  0.1101  0.1029   \n",
       "...         ...          ...          ...     ...     ...     ...     ...   \n",
       "5191     0.0671       0.2700       0.2029  0.0634  0.2220  0.1586  0.0594   \n",
       "13418    0.0918       0.1302       0.0384  0.0544  0.0898  0.0354  0.0873   \n",
       "5390     0.0689       0.1559       0.0870  0.0528  0.1230  0.0702  0.0547   \n",
       "860      0.0871       0.2039       0.1168  0.1533  0.2362  0.0829  0.0985   \n",
       "7270     0.0787       0.5220       0.4433  0.0755  0.2508  0.1753  0.0436   \n",
       "\n",
       "       DD.i.e  UD.i.e     H.e  ...  DD.a.n  UD.a.n     H.n  DD.n.l  UD.n.l  \\\n",
       "9355   0.1684  0.1082  0.0757  ...  0.1504  0.0204  0.0504  0.1846  0.1342   \n",
       "3013   0.0890  0.0161  0.0887  ...  0.0771 -0.0095  0.0753  0.1012  0.0259   \n",
       "1475   0.1347  0.0343  0.1095  ...  0.1210  0.0104  0.0679  0.0977  0.0298   \n",
       "7420   0.0762 -0.0043  0.0966  ...  0.1452  0.0605  0.0525  0.1522  0.0997   \n",
       "6903   0.2811  0.1782  0.1679  ...  0.3239  0.2059  0.1201  0.3069  0.1868   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "5191   0.1365  0.0771  0.0613  ...  0.1064  0.0378  0.0565  0.2103  0.1538   \n",
       "13418  0.1034  0.0161  0.0464  ...  0.0125 -0.0847  0.1051  0.0818 -0.0233   \n",
       "5390   0.0787  0.0240  0.0565  ...  0.1223  0.0354  0.0407  0.4830  0.4423   \n",
       "860    0.1993  0.1008  0.1230  ...  0.1574  0.0204  0.0747  0.2438  0.1691   \n",
       "7270   0.4767  0.4331  0.0599  ...  0.1469  0.0265  0.0729  0.1782  0.1053   \n",
       "\n",
       "          H.l  DD.l.Return  UD.l.Return  H.Return  output  \n",
       "9355   0.0902       0.4087       0.3185    0.0857       0  \n",
       "3013   0.0697       0.1804       0.1107    0.0781       0  \n",
       "1475   0.1059       0.4267       0.3208    0.1138       0  \n",
       "7420   0.0834       0.2212       0.1378    0.0541       0  \n",
       "6903   0.0884       0.3295       0.2411    0.0787       0  \n",
       "...       ...          ...          ...       ...     ...  \n",
       "5191   0.0750       0.2660       0.1910    0.0737       0  \n",
       "13418  0.0797       0.1392       0.0595    0.1005       0  \n",
       "5390   0.0718       0.2617       0.1899    0.0573       0  \n",
       "860    0.0942       0.4139       0.3197    0.0890       0  \n",
       "7270   0.0985       0.3348       0.2363    0.0694       0  \n",
       "\n",
       "[14600 rows x 32 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "beb77054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>H.e</th>\n",
       "      <th>...</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0810</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>-0.0227</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>-0.0618</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>-0.0174</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>0.1198</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.1746</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5183</th>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1087</td>\n",
       "      <td>-0.0191</td>\n",
       "      <td>0.1152</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.5173</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>-0.0254</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.0987</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>-0.0317</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.2546</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2921 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i     H.i  \\\n",
       "169      0.0810       0.1129       0.0319  0.0795  0.1331  0.0536  0.0539   \n",
       "9355     0.0952       0.3704       0.2752  0.1018  0.1374  0.0356  0.0602   \n",
       "3013     0.0689       0.1374       0.0685  0.0636  0.0969  0.0333  0.0729   \n",
       "1475     0.1037       0.1997       0.0960  0.1017  0.0998 -0.0019  0.1004   \n",
       "7420     0.1008       0.3650       0.2642  0.1002  0.1622  0.0620  0.0805   \n",
       "...         ...          ...          ...     ...     ...     ...     ...   \n",
       "740      0.1161       0.1759       0.0598  0.1138  0.1431  0.0293  0.1132   \n",
       "3461     0.0647       0.1375       0.0728  0.0478  0.1101  0.0623  0.0483   \n",
       "5183     0.0618       0.1744       0.1126  0.0489  0.1236  0.0747  0.0444   \n",
       "1188     0.1164       0.1929       0.0765  0.0705  0.1038  0.0333  0.0800   \n",
       "13093    0.0480       0.5173       0.4693  0.0895  0.0641 -0.0254  0.1091   \n",
       "\n",
       "       DD.i.e  UD.i.e     H.e  ...  DD.a.n  UD.a.n     H.n  DD.n.l  UD.n.l  \\\n",
       "169    0.0787  0.0248  0.0768  ...  0.1281  0.0196  0.0813  0.1998  0.1185   \n",
       "9355   0.1684  0.1082  0.0757  ...  0.1504  0.0204  0.0504  0.1846  0.1342   \n",
       "3013   0.0890  0.0161  0.0887  ...  0.0771 -0.0095  0.0753  0.1012  0.0259   \n",
       "1475   0.1347  0.0343  0.1095  ...  0.1210  0.0104  0.0679  0.0977  0.0298   \n",
       "7420   0.0762 -0.0043  0.0966  ...  0.1452  0.0605  0.0525  0.1522  0.0997   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "740    0.0905 -0.0227  0.0702  ...  0.0795 -0.0618  0.0819  0.1363  0.0544   \n",
       "3461   0.0842  0.0359  0.0647  ...  0.0542 -0.0174  0.0634  0.1832  0.1198   \n",
       "5183   0.0830  0.0386  0.0589  ...  0.1046  0.0360  0.0515  0.2130  0.1615   \n",
       "1188   0.1048  0.0248  0.1040  ...  0.1122  0.0143  0.1278  0.1087 -0.0191   \n",
       "13093  0.0964 -0.0127  0.0694  ...  0.1784  0.0987  0.0921  0.0604 -0.0317   \n",
       "\n",
       "          H.l  DD.l.Return  UD.l.Return  H.Return  output  \n",
       "169    0.0913       0.2297       0.1384    0.0568       1  \n",
       "9355   0.0902       0.4087       0.3185    0.0857       0  \n",
       "3013   0.0697       0.1804       0.1107    0.0781       0  \n",
       "1475   0.1059       0.4267       0.3208    0.1138       0  \n",
       "7420   0.0834       0.2212       0.1378    0.0541       0  \n",
       "...       ...          ...          ...       ...     ...  \n",
       "740    0.1074       0.2189       0.1115    0.0863       0  \n",
       "3461   0.0739       0.1746       0.1007    0.0650       0  \n",
       "5183   0.0478       0.1889       0.1411    0.0618       0  \n",
       "1188   0.1152       0.2360       0.1208    0.0892       0  \n",
       "13093  0.0979       0.3525       0.2546    0.0768       0  \n",
       "\n",
       "[2921 rows x 32 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b8bf01e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "0    11455\n",
       "1      225\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "374db2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = dataset[dataset['output'] == 0]\n",
    "df_1 = dataset[dataset['output'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2fca9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_down = df_0.sample(n=2*len(df_1), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7cbeef0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "0    572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0_down['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c0834a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_0_down,df_1],ignore_index=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5ee4172e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>DD.i.e</th>\n",
       "      <th>UD.i.e</th>\n",
       "      <th>H.e</th>\n",
       "      <th>...</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.2993</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0987</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>-0.0285</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>-0.0341</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0930</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.1198</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>-0.0264</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>-0.0280</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.1029</td>\n",
       "      <td>0.1393</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>-0.0813</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.1006</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>-0.0794</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>-0.0253</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.2971</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     H.period  DD.period.t  UD.period.t     H.t  DD.t.i  UD.t.i     H.i  \\\n",
       "0      0.0760       0.2769       0.2009  0.0509  0.1306  0.0797  0.0565   \n",
       "1      0.0987       0.1229       0.0242  0.0438  0.0926  0.0488  0.1005   \n",
       "2      0.0781       0.1711       0.0930  0.0749  0.0879  0.0130  0.0591   \n",
       "3      0.0642       0.1021       0.0379  0.0839  0.1159  0.0320  0.0713   \n",
       "4      0.0594       0.6023       0.5429  0.0747  0.0483 -0.0264  0.1083   \n",
       "..        ...          ...          ...     ...     ...     ...     ...   \n",
       "853    0.1029       0.1393       0.0364  0.0729  0.1278  0.0549  0.0771   \n",
       "854    0.1428       0.2256       0.0828  0.0961  0.1199  0.0238  0.1154   \n",
       "855    0.1417       0.1957       0.0540  0.0940  0.1389  0.0449  0.1006   \n",
       "856    0.1665       0.2393       0.0728  0.1148  0.1478  0.0330  0.1043   \n",
       "857    0.1502       0.2114       0.0612  0.0650  0.1302  0.0652  0.0985   \n",
       "\n",
       "     DD.i.e  UD.i.e     H.e  ...  DD.a.n  UD.a.n     H.n  DD.n.l  UD.n.l  \\\n",
       "0    0.1781  0.1216  0.0715  ...  0.2079  0.1390  0.1205  0.1450  0.0245   \n",
       "1    0.0770 -0.0235  0.0409  ...  0.1103 -0.0285  0.0974  0.0633 -0.0341   \n",
       "2    0.1090  0.0499  0.0820  ...  0.0982  0.0159  0.0686  0.1198  0.0512   \n",
       "3    0.1043  0.0330  0.0652  ...  0.0777  0.0257  0.0626  0.1795  0.1169   \n",
       "4    0.0932 -0.0151  0.0718  ...  0.3450  0.3028  0.0794  0.0514 -0.0280   \n",
       "..      ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "853  0.0982  0.0211  0.0837  ...  0.1342  0.0220  0.0776  0.1731  0.0955   \n",
       "854  0.1344  0.0190  0.0998  ...  0.0700 -0.0813  0.1115  0.1669  0.0554   \n",
       "855  0.1320  0.0314  0.0934  ...  0.0521 -0.0794  0.1243  0.2647  0.1404   \n",
       "856  0.1526  0.0483  0.0879  ...  0.1296 -0.0253  0.0934  0.2056  0.1122   \n",
       "857  0.1249  0.0264  0.0908  ...  0.1587  0.0375  0.0845  0.1990  0.1145   \n",
       "\n",
       "        H.l  DD.l.Return  UD.l.Return  H.Return  output  \n",
       "0    0.1108       0.2993       0.1885    0.0844       0  \n",
       "1    0.0610       0.1247       0.0637    0.1187       0  \n",
       "2    0.0968       0.1948       0.0980    0.0813       0  \n",
       "3    0.0876       0.1313       0.0437    0.0787       0  \n",
       "4    0.1003       0.6368       0.5365    0.0768       0  \n",
       "..      ...          ...          ...       ...     ...  \n",
       "853  0.0884       0.2158       0.1274    0.1072       1  \n",
       "854  0.1420       0.2984       0.1564    0.1132       1  \n",
       "855  0.1185       0.2517       0.1332    0.0940       1  \n",
       "856  0.1433       0.2870       0.1437    0.1373       1  \n",
       "857  0.1061       0.2971       0.1910    0.1014       1  \n",
       "\n",
       "[858 rows x 32 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c83f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df,y_train,y_test = train_test_split(df_final,test_size=0.2,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45b45ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "0    459\n",
       "1    227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6037bcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "0    113\n",
       "1     59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e2712db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test_set2point7std.csv\",index=False)\n",
    "train_df.to_csv(\"train_set2point7std.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908f1935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the top-level package for core functionality\n",
    "\n",
    "# Import neural network functionality\n",
    "\n",
    "# Import functional programming tools\n",
    "\n",
    "# Import optimization functionality\n",
    "\n",
    "# Import dataset functions\n",
    "\n",
    "# Import evaluation metrics\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6175cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f3e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_set2point7std.csv')\n",
    "test_df = pd.read_csv('test_set2point7std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a10c2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21e8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['output'],axis='columns').values\n",
    "Y = train_df['output'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e05fc241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2015daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.tensor(X).float(),torch.tensor(Y).float())\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1497970",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(31,16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,1),\n",
    "    nn.Sigmoid()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c233a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6457, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7693, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7151, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6138, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5488, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 1: loss = 0.6344\n",
      "tensor(0.7148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5656, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6747, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6345, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 2: loss = 0.5738\n",
      "tensor(0.5121, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3942, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3692, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 3: loss = 0.4577\n",
      "tensor(0.5219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3557, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3840, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4270, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3766, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2575, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4170, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 4: loss = 0.4074\n",
      "tensor(0.2333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2553, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4085, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2673, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4012, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7017, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4384, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 5: loss = 0.4077\n",
      "tensor(0.2363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2420, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2084, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2696, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2768, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2980, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3807, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3648, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5127, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4660, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3787, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 6: loss = 0.3534\n",
      "tensor(0.4701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3020, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3964, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2559, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3097, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2875, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3916, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 7: loss = 0.3607\n",
      "tensor(0.2990, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3191, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4535, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2313, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3297, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4185, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3154, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4201, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 8: loss = 0.3224\n",
      "tensor(0.2195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1734, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2123, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2671, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4337, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1731, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 9: loss = 0.2836\n",
      "tensor(0.3235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2548, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1776, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1774, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 10: loss = 0.2917\n",
      "tensor(0.3355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3558, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2361, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1489, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4545, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2460, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2530, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1560, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3998, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2536, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 11: loss = 0.2689\n",
      "tensor(0.3161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2145, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3828, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3377, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1294, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 12: loss = 0.2603\n",
      "tensor(0.2192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1672, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2195, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3411, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2228, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2987, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1963, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5030, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 13: loss = 0.2666\n",
      "tensor(0.2721, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3222, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2209, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2046, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3227, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4107, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 14: loss = 0.2811\n",
      "tensor(0.4199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3769, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2778, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2523, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1509, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1358, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2197, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1564, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3284, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 15: loss = 0.2663\n",
      "tensor(0.4177, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1103, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1136, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1089, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1615, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 16: loss = 0.2621\n",
      "tensor(0.3258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4429, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1869, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2315, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1149, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1375, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2022, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 17: loss = 0.2386\n",
      "tensor(0.2332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1698, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2088, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2484, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4770, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3542, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 18: loss = 0.2628\n",
      "tensor(0.1711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2704, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2569, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1382, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 19: loss = 0.2465\n",
      "tensor(0.1961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1876, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2578, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1865, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1852, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1365, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2231, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 20: loss = 0.2639\n",
      "tensor(0.3389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2407, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1242, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1605, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1655, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1667, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 21: loss = 0.2397\n",
      "tensor(0.1343, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0830, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2250, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1681, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3567, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3067, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2334, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3292, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1740, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4246, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 22: loss = 0.2369\n",
      "tensor(0.1339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2095, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3940, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3091, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1409, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 23: loss = 0.2142\n",
      "tensor(0.2540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1076, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1373, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2421, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4081, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2286, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3280, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 24: loss = 0.2161\n",
      "tensor(0.2110, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1826, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1083, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1983, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1391, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1936, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 25: loss = 0.2435\n",
      "tensor(0.3059, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4175, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3923, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2499, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2064, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2047, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2453, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 26: loss = 0.2518\n",
      "tensor(0.3118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3618, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0613, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4494, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1788, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5146, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3793, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2652, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3485, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 27: loss = 0.2608\n",
      "tensor(0.2287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0991, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1598, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1844, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1335, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2729, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1362, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3654, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1815, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 28: loss = 0.2466\n",
      "tensor(0.1169, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1155, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2031, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2737, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1255, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2743, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3418, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2458, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3096, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 29: loss = 0.2055\n",
      "tensor(0.3038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1772, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0977, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1995, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2827, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1855, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1633, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1947, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2805, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1834, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2385, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 30: loss = 0.2153\n",
      "tensor(0.3163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1640, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0582, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1644, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1477, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1625, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1989, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2981, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3599, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 31: loss = 0.2050\n",
      "tensor(0.1516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1763, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1196, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2751, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1287, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1252, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1668, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2474, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2174, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2379, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 32: loss = 0.1949\n",
      "tensor(0.2330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1026, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1812, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4086, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2666, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1055, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1419, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2468, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1745, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0956, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4262, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1617, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1649, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 33: loss = 0.2218\n",
      "tensor(0.0908, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1119, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1187, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1953, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3730, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1897, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1399, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0866, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2528, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2415, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2321, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2676, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 34: loss = 0.1990\n",
      "tensor(0.1699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1496, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2068, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1316, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1176, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3021, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2367, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0752, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2120, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1324, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1370, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0762, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2309, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 35: loss = 0.1799\n",
      "tensor(0.1887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2034, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1675, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1434, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0864, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2577, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1115, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4178, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1804, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0794, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1238, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3727, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 36: loss = 0.1919\n",
      "tensor(0.0831, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2426, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0715, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0624, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2289, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3019, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1966, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0482, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 37: loss = 0.1685\n",
      "tensor(0.0934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1307, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1870, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2004, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2000, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2098, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2584, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1211, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2203, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1665, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 38: loss = 0.1709\n",
      "tensor(0.1595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2230, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2659, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0662, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2350, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1526, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2041, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2520, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2225, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1464, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2272, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 39: loss = 0.1646\n",
      "tensor(0.1398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1454, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1171, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1911, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1919, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0904, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0944, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1215, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3742, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0403, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0892, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 40: loss = 0.1446\n",
      "tensor(0.1881, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1952, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1917, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0782, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2181, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0765, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0871, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2049, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0111, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 41: loss = 0.1646\n",
      "tensor(0.0508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1208, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0478, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1352, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1380, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1325, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1697, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2400, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1950, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0476, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3078, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 42: loss = 0.1518\n",
      "tensor(0.2006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0707, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3224, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2332, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1439, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1202, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2184, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1251, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0641, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2298, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1356, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1038, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1194, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2048, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 43: loss = 0.1629\n",
      "tensor(0.1645, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1820, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0423, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2846, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1220, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1449, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1104, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1254, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1512, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2072, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2749, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1896, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 44: loss = 0.1648\n",
      "tensor(0.1226, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1467, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1402, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1093, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2780, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1760, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1273, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0459, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1243, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2065, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2711, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1263, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0428, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 45: loss = 0.1387\n",
      "tensor(0.1109, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0395, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5266, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0591, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0791, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2872, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1069, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2341, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0630, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0516, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0621, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2063, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1663, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1684, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 46: loss = 0.1555\n",
      "tensor(0.1199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2851, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1898, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1691, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1513, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1619, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1801, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2122, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1376, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1594, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0758, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1821, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 47: loss = 0.1616\n",
      "tensor(0.1189, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1563, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1339, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1543, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1274, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0939, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0810, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0378, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1636, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0724, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2005, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1792, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1001, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0408, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 48: loss = 0.1275\n",
      "tensor(0.0755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1581, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1237, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2432, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1431, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0331, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3993, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2317, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3080, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1364, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2168, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0614, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0490, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 49: loss = 0.1571\n",
      "tensor(0.1817, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1424, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0504, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0610, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2976, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1808, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1392, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1609, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1039, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch 50: loss = 0.1236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr= 0.3, momentum= 0.80)\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        features,targets = data\n",
    "        targets = targets.unsqueeze(1).float()\n",
    "        predictions = model(features)\n",
    "        loss = loss_criterion(predictions, targets)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: loss = {epoch_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e333410",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(['output'],axis='columns').values\n",
    "Y_test = test_df['output'].values\n",
    "dataset_test = TensorDataset(torch.tensor(X_test).float(),torch.tensor(Y_test).float())\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "227ec1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1356\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # IMPORTANT: evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():  # no gradients during testing\n",
    "    for features, targets in dataloader_test:\n",
    "        targets = targets.unsqueeze(1).float()\n",
    "\n",
    "        predictions = model(features)\n",
    "        loss = loss_criterion(predictions, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(dataloader_test)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb90f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
